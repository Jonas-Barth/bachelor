{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the pysentimiento calculations file\n",
    "# pip install pysentimiento\n",
    "from pysentimiento import create_analyzer\n",
    "analyzer = create_analyzer(task=\"irony\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'analyzer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test cell to test how it works\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43manalyzer\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWow... soooo cool\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mtype\u001b[39m(result\u001b[38;5;241m.\u001b[39mprobas[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mironic\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'analyzer' is not defined"
     ]
    }
   ],
   "source": [
    "# Test cell to test how it works\n",
    "result = analyzer.predict('Wow... soooo cool')\n",
    "type(result.probas['ironic'])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFScore(truepos, trueneg, falsepos, falseneg):\n",
    "    FScoreResults = {}\n",
    "    FScoreResults['accuracy'] = (truepos + trueneg)/(truepos + trueneg + falsepos + falseneg)\n",
    "    FScoreResults['accuracy'] = (truepos + trueneg)/(truepos + trueneg + falsepos + falseneg)\n",
    "    if (truepos + falsepos > 0):\n",
    "        FScoreResults['precision'] = truepos/(truepos + falsepos)\n",
    "    else:\n",
    "        FScoreResults['precision'] = 0\n",
    "\n",
    "    if(truepos + falseneg > 0):\n",
    "        FScoreResults['recall'] = truepos/(truepos + falseneg)\n",
    "    else:\n",
    "        FScoreResults['recall'] = 0\n",
    "        \n",
    "    if((FScoreResults['precision'] + FScoreResults['recall']) > 0):\n",
    "        FScoreResults['F1'] = (2 * FScoreResults['precision'] * FScoreResults['recall'])/(FScoreResults['precision'] + FScoreResults['recall'])\n",
    "    else:\n",
    "        FScoreResults['F1'] = 0\n",
    "    return FScoreResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the scores based on the answers from pysentimiento, this method is simply adapted from the other scores methods for GPT\n",
    "def scoresSentimiento(dataset, resultColumn):\n",
    "    truepos = 0\n",
    "    falsepos = 0\n",
    "    trueneg = 0\n",
    "    falseneg = 0\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        sentimientoEval = row[resultColumn]\n",
    "        if (int(row[1]) == 1):\n",
    "            if (int(sentimientoEval) == 1):\n",
    "                truepos = truepos + 1\n",
    "            else:\n",
    "                falseneg = falseneg + 1\n",
    "        elif (int(row[1]) == 0):\n",
    "            if (int(sentimientoEval) == 1):\n",
    "                falsepos = falsepos + 1\n",
    "            else:\n",
    "                trueneg = trueneg + 1\n",
    "\n",
    "    numResults = calcFScore(truepos, trueneg, falsepos, falseneg)\n",
    "    numResults['tp'] = truepos\n",
    "    numResults['fp'] = falsepos\n",
    "    numResults['fn'] = falseneg\n",
    "    numResults['tn'] = trueneg\n",
    "    return numResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.79,\n",
       " 'precision': 0.7592592592592593,\n",
       " 'recall': 0.8367346938775511,\n",
       " 'F1': 0.796116504854369,\n",
       " 'tp': 41,\n",
       " 'fp': 13,\n",
       " 'fn': 8,\n",
       " 'tn': 38}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converts responses to 1 or 0 classification with threshold 0.5\n",
    "import pandas as pd\n",
    "\n",
    "datasetName = \"manual_select_odd\"\n",
    "datasetPath = \"datasets\\\\\" + datasetName + \".csv\"\n",
    "data = pd.read_csv(datasetPath)\n",
    "data = data.head(100)\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    result = analyzer.predict(row[0])\n",
    "    if(result.probas['ironic'] >= 0.5):\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "data['result'] = results\n",
    "scores = scoresSentimiento(data, 2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN CELL does the analysis and creates the metadata file for this run type\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "datasetName = \"manual_select_odd\"\n",
    "datasetPath = \"datasets\\\\\" + datasetName + \".csv\"\n",
    "data = pd.read_csv(datasetPath)\n",
    "data = data.head(100)\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    result = analyzer.predict(row[0])\n",
    "    if(result.probas['ironic'] >= 0.5):\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "data['result'] = results\n",
    "scores = scoresSentimiento(data, 2)\n",
    "scores\n",
    "\n",
    "linesToWrite = ['Results for Pysentimiento using dataset ' + datasetName +  ': \\n',\n",
    "        'Confusion Matrix:' + '\\n',\n",
    "        str(scores['tp']) + '  ' + str(scores['fn']) + '\\n',\n",
    "        str(scores['fp']) + '  ' + str(scores['tn']) + '\\n',\n",
    "        'Accuracy: ' + str(scores['accuracy']) + '\\n',\n",
    "        'Precision: ' + str(scores['precision']) + '\\n',\n",
    "        'Recall: ' + str(scores['recall']) + '\\n',\n",
    "        'F1-Score: ' + str(scores['F1']) + '\\n\\n']\n",
    "\n",
    "path = \"Other LLMs\\\\pysentimiento results\\\\\" + datasetName\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "file = open(path + \"\\\\metadata.txt\", \"w\")\n",
    "\n",
    "data.to_csv(path + \"\\\\results.csv\", index=False)\n",
    "\n",
    "file.writelines(linesToWrite)\n",
    "file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
