{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/pysentimiento/bertweet-irony/resolve/main/config.json from cache at C:\\Users\\Jonas/.cache\\huggingface\\transformers\\f8c3d0ff828a053eda9e09e31cffe4f34357b5f0db0a652e691a0cd8ddec65d7.cadb6579ef708993a8e8fe1203d7ec58dc0995c322918e64365f30f3f224a3c7\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"pysentimiento/bertweet-irony\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"not ironic\",\n",
      "    \"1\": \"ironic\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"ironic\": 1,\n",
      "    \"not ironic\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 130,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"tokenizer_class\": \"BertweetTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 64001\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/pysentimiento/bertweet-irony/resolve/main/pytorch_model.bin from cache at C:\\Users\\Jonas/.cache\\huggingface\\transformers\\3c06aefe193d31291576f9a72b314ba25674d4862efa3acb1de53f11553e344a.52b23769730358eb08c6fd9354853acb0d9df87c2db836bf621c0cd6445419a2\n",
      "All model checkpoint weights were used when initializing RobertaForSequenceClassification.\n",
      "\n",
      "All the weights of RobertaForSequenceClassification were initialized from the model checkpoint at pysentimiento/bertweet-irony.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use RobertaForSequenceClassification for predictions without further training.\n",
      "loading file https://huggingface.co/pysentimiento/bertweet-irony/resolve/main/vocab.txt from cache at C:\\Users\\Jonas/.cache\\huggingface\\transformers\\6ff6abac040e0199758cfcddcaab5c9add70906449d671106a9a8a1f7302a239.f8a4dfe5c3c45a26f9df849d732decb191dc0c05ab270799695430332d143982\n",
      "loading file https://huggingface.co/pysentimiento/bertweet-irony/resolve/main/bpe.codes from cache at C:\\Users\\Jonas/.cache\\huggingface\\transformers\\f129dfa1e9a848a27a01f065bc17f02c025e926d171404e8cec1f8ee6b62a72e.75877d86011e5d5d46614d3a21757b705e9d20ed45a019805d25159b4837b0a4\n",
      "loading file https://huggingface.co/pysentimiento/bertweet-irony/resolve/main/added_tokens.json from cache at C:\\Users\\Jonas/.cache\\huggingface\\transformers\\a31445a732adf6792d720602c7931d26f42ec85e14beb86bae51b16df8ad42c7.99342f91bcc91195061d858c5ed9d0f61d2a8b6d7e3ef661b2a10fcacadecace\n",
      "loading file https://huggingface.co/pysentimiento/bertweet-irony/resolve/main/special_tokens_map.json from cache at C:\\Users\\Jonas/.cache\\huggingface\\transformers\\ac9fa529e4f4ab8145d47a0616325429d722a48c4f7793987eb12bc6b0291fea.adf9ca26cf9cb894c06d81ab14f4ad5657962a0f38dbf8000649a29331641b87\n",
      "loading file https://huggingface.co/pysentimiento/bertweet-irony/resolve/main/tokenizer_config.json from cache at C:\\Users\\Jonas/.cache\\huggingface\\transformers\\3aabc2b5609b818f4a383b16b8db722083edc71bf979b92bde8a8c5c720259f1.1b1116b508debe8249fd2fba56ea9d54773552608ba16dc8f1ae2676e1073a18\n",
      "Adding <mask> to the vocabulary\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from pysentimiento import create_analyzer\n",
    "analyzer = create_analyzer(task=\"irony\", lang=\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taken from gpt.ipynb file\n",
    "def calcFScore(truepos, falsepos, falseneg):\n",
    "    FScoreResults = {}\n",
    "    FScoreResults['precision'] = truepos/(truepos + falsepos)\n",
    "    FScoreResults['recall'] = truepos/(truepos + falseneg)\n",
    "    FScoreResults['F1'] = (2 * FScoreResults['precision'] * FScoreResults['recall'])/(FScoreResults['precision'] + FScoreResults['recall'])\n",
    "    return FScoreResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the scores based on the answers from pysentimiento, this method is simply adapted from the other scores methods for GPT\n",
    "def scoresSentimiento(dataset, resultColumn):\n",
    "    truepos = 0\n",
    "    falsepos = 0\n",
    "    trueneg = 0\n",
    "    falseneg = 0\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        sentimientoEval = row[resultColumn]\n",
    "        if (int(row[1]) == 1):\n",
    "            if (int(sentimientoEval) == 1):\n",
    "                truepos = truepos + 1\n",
    "            else:\n",
    "                falseneg = falseneg + 1\n",
    "        elif (int(row[1]) == 0):\n",
    "            if (int(sentimientoEval) == 1):\n",
    "                falsepos = falsepos + 1\n",
    "            else:\n",
    "                trueneg = trueneg + 1\n",
    "\n",
    "    numResults = calcFScore(truepos, falsepos, falseneg)\n",
    "    numResults['tp'] = truepos\n",
    "    numResults['fp'] = falsepos\n",
    "    numResults['fn'] = falseneg\n",
    "    numResults['tn'] = trueneg\n",
    "    return numResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.4864864864864865,\n",
       " 'recall': 0.6206896551724138,\n",
       " 'F1': 0.5454545454545455,\n",
       " 'tp': 18,\n",
       " 'fp': 19,\n",
       " 'fn': 11,\n",
       " 'tn': 52}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datasetName = \"fixedsetreadin\"\n",
    "datasetPath = \"datasets\\\\\" + datasetName + \".csv\"\n",
    "data = pd.read_csv(datasetPath)\n",
    "data = data.head(100)\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    result = analyzer.predict(row[0])\n",
    "    if(result.probas['ironic'] >= 0.5):\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "data['result'] = results\n",
    "scores = scoresSentimiento(data, 2)\n",
    "scores # F1 82/103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.7592592592592593,\n",
       " 'recall': 0.8367346938775511,\n",
       " 'F1': 0.796116504854369,\n",
       " 'tp': 41,\n",
       " 'fp': 13,\n",
       " 'fn': 8,\n",
       " 'tn': 38}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datasetName = \"tweet_eval_irony_train\"\n",
    "datasetPath = \"datasets\\\\\" + datasetName + \".csv\"\n",
    "data = pd.read_csv(datasetPath)\n",
    "data = data.head(100)\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    result = analyzer.predict(row[0])\n",
    "    if(result.probas['ironic'] >= 0.5):\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "data['result'] = results\n",
    "scores = scoresSentimiento(data, 2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.6721311475409836,\n",
       " 'recall': 0.9761904761904762,\n",
       " 'F1': 0.7961165048543689,\n",
       " 'tp': 41,\n",
       " 'fp': 20,\n",
       " 'fn': 1,\n",
       " 'tn': 38}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "datasetName = \"tweet_eval_irony_test\"\n",
    "datasetPath = \"datasets\\\\\" + datasetName + \".csv\"\n",
    "data = pd.read_csv(datasetPath)\n",
    "data = data.head(100)\n",
    "\n",
    "results = []\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    result = analyzer.predict(row[0])\n",
    "    if(result.probas['ironic'] >= 0.5):\n",
    "        results.append(1)\n",
    "    else:\n",
    "        results.append(0)\n",
    "\n",
    "data['result'] = results\n",
    "scores = scoresSentimiento(data, 2)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
