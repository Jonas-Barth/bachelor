{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = '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'   #  OLD KEY\n",
    "#key = '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'\n",
    "import os\n",
    "import pandas as pd\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATASET FROM ONLINE\n",
    "\n",
    "#from datasets import load_dataset\n",
    "\n",
    "#dataset = load_dataset(\"tweet_eval\", \"irony\")\n",
    "\n",
    "#for index, row in dataset.iterrows():\n",
    "#    print(row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gptNoHistory (dataset, sysprompt, modelName):\n",
    "    client = OpenAI(api_key = key)\n",
    "    #results = {}\n",
    "    content = []\n",
    "    resultEval = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        startmsg = [{\"role\": \"system\", \"content\": sysprompt}, {\"role\": \"user\", \"content\": row[0]}]\n",
    "        chat_completion = client.chat.completions.create(messages = startmsg, model = modelName)\n",
    "        if ((index + 1) % 20 == 0):\n",
    "            print(index + 1, ((index + 1)/len(dataset)) * 100, \"%\")\n",
    "        #results[row[0]] = chat_completion.choices[0].message.content\n",
    "        content.append(row[0])\n",
    "        resultEval.append(chat_completion.choices[0].message.content)\n",
    "    \n",
    "    resultData = {\n",
    "        'content': content,\n",
    "        'classification': resultEval,\n",
    "        'model': chat_completion.model\n",
    "    }\n",
    "    results = pd.DataFrame(resultData)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gptAreYouSure (dataset, sysprompt, modelName):\n",
    "    client = OpenAI(api_key = key)\n",
    "    resultSure = []\n",
    "\n",
    "    for index, row in dataset.iterrows():\n",
    "        message_history = [{\"role\": \"system\", \"content\": sysprompt}]\n",
    "        message_history.append({\"role\": \"user\", \"content\": row[0]})\n",
    "        chat_completion = client.chat.completions.create(messages = message_history, model = modelName)\n",
    "        resultString = chat_completion.choices[0].message.content\n",
    "        message_history.append({\"role\": chat_completion.choices[0].message.role, \"content\": chat_completion.choices[0].message.content})\n",
    "        message_history.append({\"role\": \"user\", \"content\": \"Are you sure? Answer with 'Yes' or 'No'.\"})\n",
    "        chat_completion = client.chat.completions.create(messages = message_history, model = modelName)\n",
    "        resultString = resultString + ' ' + chat_completion.choices[0].message.content\n",
    "        if ((index + 1) % 20 == 0):\n",
    "            print('Progress:', index + 1, ((index + 1)/len(dataset)) * 100, \"%\")\n",
    "        resultSure.append(resultString)\n",
    "    return resultSure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT USE AS TOKEN LENGTH BECOMES TOO LARGE AND MAKES THE KEY RUN OUT OF AVAILABLE TOKENS FAST\n",
    "\n",
    "\n",
    "#def gptWithHistory (dataset, sysprompt, modelName):\n",
    "#    client = OpenAI(api_key = key)\n",
    "\n",
    "#    results = {}\n",
    "#    message_history = [{\"role\": \"system\", \"content\": sysprompt}]\n",
    "\n",
    "#    for index, row in dataset.iterrows():\n",
    "#        message_history.append({\"role\": \"user\", \"content\": row[0]}) # add tweet to the messages\n",
    "#        chat_completion = client.chat.completions.create(messages = message_history, model = modelName)\n",
    "#        message_history.append({\"role\": chat_completion.choices[0].message.role, \"content\": chat_completion.choices[0].message.content})\n",
    "#        if ((index + 1) % 20 == 0):\n",
    "#            print('Progress:', index + 1, ((index + 1)/len(dataset)) * 100, \"%\")\n",
    "#        results[row[0]] = chat_completion.choices[0].message.content\n",
    "#    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcFScore(truepos, falsepos, falseneg):\n",
    "    FScoreResults = {}\n",
    "    FScoreResults['precision'] = truepos/(truepos + falsepos)\n",
    "    FScoreResults['recall'] = truepos/(truepos + falseneg)\n",
    "    FScoreResults['F1'] = (2 * FScoreResults['precision'] * FScoreResults['recall'])/(FScoreResults['precision'] + FScoreResults['recall'])\n",
    "    return FScoreResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def matrixPlot (tp, fp, fn, tn, path, runNum):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    #tp = np.array([10, 50 ,40])\n",
    "    #fp = np.array([50, 40, 30])\n",
    "    #fn = np.array([80, 90, 60])\n",
    "    #tn = np.array([80, 90, 60])\n",
    "\n",
    "    tp_mean = np.mean(tp)\n",
    "    fp_mean = np.mean(fp)\n",
    "    fn_mean = np.mean(fn)\n",
    "    tn_mean = np.mean(tn)\n",
    "\n",
    "    tp_std = np.std(tp)\n",
    "    fp_std = np.std(fp)\n",
    "    fn_std = np.std(fn)\n",
    "    tn_std = np.std(tn)\n",
    "\n",
    "    labels = ['True Positive (' + str(len(tp)) + ')', 'False Positive (' + str(len(fp)) + ')', 'False Negative (' + str(len(fn)) + ')', 'True Negative (' + str(len(tn)) + ')']\n",
    "    x_pos = np.arange(len(labels))\n",
    "    CTEs = [tp_mean, fp_mean, fn_mean, tn_mean]\n",
    "    error = [tp_std, fp_std, fn_std, tn_std]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, CTEs, yerr=error, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Degree of confidence in evaluation')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title('Confidence comparison separated into correctness')\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.ylim(0, 100)\n",
    "\n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path + '\\\\Figure Run ' + str(runNum + 1))\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def matrixPlotSure(tp, tps, fp, fps, fn, fns, tn, tns, path, runNum):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    #tp = np.array([10, 50 ,40])\n",
    "    #fp = np.array([50, 40, 30])\n",
    "    #fn = np.array([80, 90, 60])\n",
    "    #tn = np.array([80, 90, 60])\n",
    "\n",
    "    labels = ['True Pos (' + str(tps) + '/' + str(tp - tps) + ')', 'False Pos (' + str(fps) + '/' + str(fp - fps) + ')', 'False Neg (' + str(fns) + '/' + str(fn - fns) + ')', 'True Neg (' + str(tns) + '/' + str(tn - tns) + ')']\n",
    "    x_pos = np.arange(len(labels))\n",
    "    CTEs = [tp, fp, fn, tn]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(x_pos, CTEs, align='center', alpha=0.5, ecolor='black', capsize=10)\n",
    "    ax.set_ylabel('Amount of answers per categorization')\n",
    "    ax.set_xticks(x_pos)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_title('Answers by binary confidence measure (Sure? Yes/No in parentheses)')\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.ylim(0, (tp + fp + fn + tn))\n",
    "\n",
    "    # Save the figure\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path + '\\\\Figure Run ' + str(runNum + 1))\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate result scores using the answers from GPT for a binary classification of irony\n",
    "# generalized for any dataset, as long as the classification from the original dataset and gpt are the same (e.g., '1' for irony and '0' for non-irony)\n",
    "def scoresBinary(resultSetScores, gptcolumn):\n",
    "    truepos = 0\n",
    "    falsepos = 0\n",
    "    trueneg = 0\n",
    "    falseneg = 0\n",
    "    errors = []\n",
    "\n",
    "    for index, row in resultSetScores.iterrows():\n",
    "        if (row[gptcolumn] == '1' or row[gptcolumn] == '0'):\n",
    "            if (int(row[1]) == int(row[gptcolumn])):\n",
    "                if (int(row[1]) == 1):\n",
    "                    truepos = truepos + 1\n",
    "                else:\n",
    "                    trueneg = trueneg + 1\n",
    "            elif (int(row[1]) == 0):\n",
    "                falsepos = falsepos + 1\n",
    "            elif (int(row[1]) == 1):\n",
    "                falseneg = falseneg + 1\n",
    "        else:\n",
    "            print(\"Failure in line \" + str(index) + \" in gpt answer column \" + str(gptcolumn - 1) + ' (answer format not correct). Error line: ' + str(row[gptcolumn]))\n",
    "            errors.append(str(row[gptcolumn]))\n",
    "\n",
    "    # matrix\n",
    "    #print(truepos, falsepos)\n",
    "    #print(falseneg, trueneg)\n",
    "\n",
    "    numResults = calcFScore(truepos, falsepos, falseneg)\n",
    "    numResults['tp'] = truepos\n",
    "    numResults['fp'] = falsepos\n",
    "    numResults['fn'] = falseneg\n",
    "    numResults['tn'] = trueneg\n",
    "    numResults['error'] = errors\n",
    "    return numResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate result scores using the answers from GPT for a binary classification of irony\n",
    "# generalized for any dataset, as long as the classification from the original dataset and gpt are the same (e.g., '1' for irony and '0' for non-irony)\n",
    "def scoresBinaryYesNo(resultSetScores, gptcolumn):\n",
    "    truepos = 0\n",
    "    falsepos = 0\n",
    "    trueneg = 0\n",
    "    falseneg = 0\n",
    "    errors = []\n",
    "\n",
    "    for index, row in resultSetScores.iterrows():\n",
    "        stringYN = row[gptcolumn].replace('.', '') # Turns \"Yes.\" or \"No.\" answers into \"Yes\" or \"No\".\n",
    "        if (stringYN == 'Yes' or stringYN == 'No'):\n",
    "            if (int(row[1]) == 1):\n",
    "                if (stringYN == 'Yes'):\n",
    "                    truepos = truepos + 1\n",
    "                else:\n",
    "                    falseneg = falseneg + 1\n",
    "            elif (int(row[1]) == 0): # usually always the case but just checking to be sure\n",
    "                if (stringYN == 'Yes'):\n",
    "                    falsepos = falsepos + 1\n",
    "                else:\n",
    "                    trueneg = trueneg + 1\n",
    "        else:\n",
    "            print(\"Failure in line \" + str(index) + \" in gpt answer column \" + str(gptcolumn - 1) + ' (answer format not correct). Error line: ' + str(row[gptcolumn]))\n",
    "            errors.append(str(row[gptcolumn]))\n",
    "\n",
    "    # matrix\n",
    "    #print(truepos, falsepos)\n",
    "    #print(falseneg, trueneg)\n",
    "\n",
    "    numResults = calcFScore(truepos, falsepos, falseneg)\n",
    "    numResults['tp'] = truepos\n",
    "    numResults['fp'] = falsepos\n",
    "    numResults['fn'] = falseneg\n",
    "    numResults['tn'] = trueneg\n",
    "    numResults['error'] = errors\n",
    "    return numResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate result scores using the answers from GPT for a binary classification of irony and an added confidence measure.\n",
    "# generalized for any dataset, as long as the classification from the original dataset and gpt are the same (e.g., '1' for irony and '0' for non-irony)\n",
    "def scoresBinaryConf(resultSetScores, gptcolumn):\n",
    "    import re\n",
    "\n",
    "    truepos = 0\n",
    "    trueposConf = []\n",
    "    falsepos = 0\n",
    "    falseposConf = []\n",
    "    trueneg = 0\n",
    "    truenegConf = []\n",
    "    falseneg = 0\n",
    "    falsenegConf = []\n",
    "    errors = []\n",
    "\n",
    "    for index, row in resultSetScores.iterrows():\n",
    "        if (re.match(r'(1|0)\\s((10(0)?)|(\\d(\\d)?))(%?)', row[gptcolumn])):\n",
    "            if (int(row[1]) == int(row[gptcolumn][0])):\n",
    "                if (int(row[1]) == 1):\n",
    "                    truepos = truepos + 1\n",
    "                    trueposConf = trueposConf + [int(row[gptcolumn][2:4])]\n",
    "                else:\n",
    "                    trueneg = trueneg + 1\n",
    "                    truenegConf = truenegConf + [int(row[gptcolumn][2:4])]\n",
    "            elif (int(row[1]) == 0):\n",
    "                falsepos = falsepos + 1\n",
    "                falseposConf = falseposConf + [int(row[gptcolumn][2:4])]\n",
    "            elif (int(row[1]) == 1):\n",
    "                falseneg = falseneg + 1\n",
    "                falsenegConf = falsenegConf + [int(row[gptcolumn][2:4])]\n",
    "        else:\n",
    "            print(\"Failure in line \" + str(index) + \" in gpt answer column \" + str(gptcolumn - 1) + ' (answer format not correct). Error line: ' + str(row[gptcolumn]))\n",
    "            errors.append(str(row[gptcolumn]))\n",
    "\n",
    "    # matrix\n",
    "    #print(truepos, falsepos)\n",
    "    #print(falseneg, trueneg)\n",
    "\n",
    "    numResults = calcFScore(truepos, falsepos, falseneg)\n",
    "    numResults['tp'] = truepos\n",
    "    numResults['tpConf'] = trueposConf\n",
    "    numResults['fp'] = falsepos\n",
    "    numResults['fpConf'] = falseposConf\n",
    "    numResults['fn'] = falseneg\n",
    "    numResults['fnConf'] = falsenegConf\n",
    "    numResults['tn'] = trueneg\n",
    "    numResults['tnConf'] = truenegConf\n",
    "    numResults['error'] = errors\n",
    "    return numResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate result scores using the answers from GPT for a binary classification of irony and an added evaluation of whether gpt is sure about its evaluation.\n",
    "# generalized for any dataset, as long as the classification from the original dataset and gpt are the same (e.g., '1' for irony and '0' for non-irony)\n",
    "def scoresBinarySure(resultSetScores, gptcolumn):\n",
    "    import re\n",
    "\n",
    "    truepos = 0\n",
    "    trueposSure = 0\n",
    "    falsepos = 0\n",
    "    falseposSure = 0\n",
    "    trueneg = 0\n",
    "    truenegSure = 0\n",
    "    falseneg = 0\n",
    "    falsenegSure = 0\n",
    "    errors = []\n",
    "\n",
    "    for index, row in resultSetScores.iterrows():\n",
    "        if (re.match(r'\\b(1|0)\\s(Yes|No)\\b', row[gptcolumn])):\n",
    "            if (int(row[1]) == int(row[gptcolumn][0])):\n",
    "                if (int(row[1]) == 1):\n",
    "                    truepos = truepos + 1\n",
    "                    if (row[gptcolumn][2:5] == 'Yes'):\n",
    "                        trueposSure = trueposSure + 1\n",
    "                else:\n",
    "                    trueneg = trueneg + 1\n",
    "                    if (row[gptcolumn][2:5] == 'Yes'):\n",
    "                        truenegSure = truenegSure + 1\n",
    "            elif (int(row[1]) == 0):\n",
    "                falsepos = falsepos + 1\n",
    "                if (row[gptcolumn][2:5] == 'Yes'):\n",
    "                    falseposSure = falseposSure + 1\n",
    "            elif (int(row[1]) == 1):\n",
    "                falseneg = falseneg + 1\n",
    "                if (row[gptcolumn][2:5] == 'Yes'):\n",
    "                    falsenegSure = falsenegSure + 1\n",
    "        else:\n",
    "            print(\"Failure in line \" + str(index) + \" in gpt answer column \" + str(gptcolumn - 1) + ' (answer format not correct). Error line: ' + str(row[gptcolumn]))\n",
    "            errors.append(str(row[gptcolumn]))\n",
    "\n",
    "    # matrix\n",
    "    #print(truepos, falsepos)\n",
    "    #print(falseneg, trueneg)\n",
    "\n",
    "    numResults = calcFScore(truepos, falsepos, falseneg)\n",
    "    numResults['tp'] = truepos\n",
    "    numResults['tpSure'] = trueposSure\n",
    "    numResults['fp'] = falsepos\n",
    "    numResults['fpSure'] = falseposSure\n",
    "    numResults['fn'] = falseneg\n",
    "    numResults['fnSure'] = falsenegSure\n",
    "    numResults['tn'] = trueneg\n",
    "    numResults['tnSure'] = truenegSure\n",
    "    numResults['error'] = errors\n",
    "    return numResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate result scores using the answers from GPT for a binary classification of irony\n",
    "# generalized for any dataset, as long as the classification from the original dataset and gpt are the same (e.g., '1' for irony and '0' for non-irony)\n",
    "def scoresSentChoice(resultSetScores, gptcolumn):\n",
    "    truepos = 0\n",
    "    falsepos = 0\n",
    "    trueneg = 0\n",
    "    falseneg = 0\n",
    "    errors = []\n",
    "\n",
    "    for index, row in resultSetScores.iterrows():\n",
    "        string = row[gptcolumn].replace('.', '') # removes possible periods at the end for more unified answer format\n",
    "        if (string.lower() in ['angry', 'sad', 'ironic', 'happy']):\n",
    "            if (int(row[1]) == 1):\n",
    "                if (string == 'ironic'):\n",
    "                    truepos = truepos + 1\n",
    "                else:\n",
    "                    falseneg = falseneg + 1\n",
    "            elif (int(row[1]) == 0): # usually always the case but just checking to be sure\n",
    "                if (string == 'ironic'):\n",
    "                    falsepos = falsepos + 1\n",
    "                else:\n",
    "                    trueneg = trueneg + 1\n",
    "        else:\n",
    "            print(\"Failure in line \" + str(index) + \" in gpt answer column \" + str(gptcolumn - 1) + ' (answer format not correct). Error line: ' + str(row[gptcolumn]))\n",
    "            errors.append(str(row[gptcolumn]))\n",
    "\n",
    "    # matrix\n",
    "    #print(truepos, falsepos)\n",
    "    #print(falseneg, trueneg)\n",
    "\n",
    "    numResults = calcFScore(truepos, falsepos, falseneg)\n",
    "    numResults['tp'] = truepos\n",
    "    numResults['fp'] = falsepos\n",
    "    numResults['fn'] = falseneg\n",
    "    numResults['tn'] = trueneg\n",
    "    numResults['error'] = errors\n",
    "    return numResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate result scores using the answers from GPT for a percentage classification of irony.\n",
    "# generalized for any dataset, as long as the classification from the original dataset and gpt are the same (e.g., '1' for irony and '0' for non-irony)\n",
    "def scoresPercentage(resultSetScores, gptcolumn):\n",
    "    import re\n",
    "\n",
    "    truepos = 0\n",
    "    falsepos = 0\n",
    "    trueneg = 0\n",
    "    falseneg = 0\n",
    "    errors = []\n",
    "\n",
    "    for index, row in resultSetScores.iterrows():\n",
    "        string = row[gptcolumn]\n",
    "        string = string[0:3]\n",
    "        string = string.replace(' ', '')\n",
    "        #print('-' + string + '-')\n",
    "        if (re.match(r'(\\d{1,2}%?|(100(%?)))$', string)):\n",
    "            if ('%' in string):\n",
    "                string = string[0:len(string) - 1] # remove % sign at end if applicable\n",
    "            result = 0\n",
    "            if (int(string) >= 50): # if an evaluation is considered by GPT to consist of 50% or more irony then the message is considered ironic for the purposes of this experiment.\n",
    "                result = 1\n",
    "            if (int(row[1]) == result):\n",
    "                if (int(row[1]) == 1):\n",
    "                    truepos = truepos + 1\n",
    "                else:\n",
    "                    trueneg = trueneg + 1\n",
    "            elif (int(row[1]) == 0):\n",
    "                falsepos = falsepos + 1\n",
    "            elif (int(row[1]) == 1):\n",
    "                falseneg = falseneg + 1\n",
    "        else:\n",
    "            print(\"Failure in line \" + str(index) + \" in gpt answer column \" + str(gptcolumn - 1) + ' (answer format not correct). Error line: ' + str(row[gptcolumn]))\n",
    "            errors.append(str(row[gptcolumn]))\n",
    "\n",
    "    numResults = calcFScore(truepos, falsepos, falseneg)\n",
    "    numResults['tp'] = truepos\n",
    "    numResults['fp'] = falsepos\n",
    "    numResults['fn'] = falseneg\n",
    "    numResults['tn'] = trueneg\n",
    "    numResults['error'] = errors\n",
    "    return numResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listAvg (numbers):\n",
    "    total_sum = sum(numbers)\n",
    "    count = len(numbers)\n",
    "    if count == 0:\n",
    "        average = 0\n",
    "    else:\n",
    "        average = total_sum / count\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seeing ppl walking w/ crutches makes me really excited for the next 3 weeks of my life\n",
      "Hey what do you know, one of the witnesses supporting Darren Wilson's story lied! And is racist! Mind blown!\n",
      "You know it's going to be a great day when you're Garmin resets itself and you spill some cinnamon down yourself  #slowclap\n",
      "Halfway thorough my workday ... Woooo\n",
      "Would like to thank my nephew for giving me his horrible cold & sore throat etc.. Much appreciated!\n",
      "I forked node!  Get ready for the future.  (Where's my interviews)\n",
      "When we stop accepting crumbs in the name of love, only then we can equally appreciate the silence of solitude & festivity of loving.\n",
      ".@CelticOwlWisdom Alert the media! Some guy on twitter has un-cited proof that evolution is wrong! Let's get his Nobel prize ready!\n",
      "Main issue with the walking dead- you forget to breathe when you're watching. So bloody good #WalkingDead\n",
      "Need to get back in to college..  #feeling #this\n",
      "@user lol how and what is a cthulhu ?? Funny autocorrect so helpful\n",
      "I refuse to be weak... #workout #motivation #fitfam\n",
      "I liked a @user video NEW Chocolate Bar Palette Review | Semi Sweet vs. Original\n",
      "Oh god I just so happens that i love really LOVE slow internet #slowinternet\n",
      "Simply having a wonderful christmas time :D\n",
      "isnt it the best when youre really tired then when you finally get in bed youre wide awake? I LOVE IT\n",
      "Breaking up with your girl so you don't have to buy her any presents ||#lowbudget #smartmove  #a #good #idea #butscheming doe\n",
      "Glad there's not a typhoon where we go on holiday in 4 weeks.  #fml\n",
      "#LOL with all due #Respect to #KobeBryant .. he is  #MJ ^_^ but damn near #Close !! #Legends\n",
      "@user @user you don't know a damned thing about baseball, do you?\n",
      "All I can say is I'm lucky.\n",
      "Xmas on the blog feat @user and @user * Read our story and share the LOVE ‚ù§Ô∏è Click the link...\n",
      "I got ready and then got to school and parked in less than 12 minutes! #miracle\n",
      "@user yeah. So as you can see, I have great success with the ladies! And I'm totally excited for having sex some more!\n",
      "@user I'll be a bit sweaty by the time I get to you!\n",
      "somebody wake me up early tomorrow ive been facing weird aches in my back since early december .,. and why do u think that relates madaka\n",
      "Fully charged my #Anker portable charger...it lasted 1/2 an hour.  Awesome #Fail\n",
      "i do occupy rent free space in his cranial cavity LOL @user\n",
      "Had to take a #PatioPics - snow falling still. This was totally clear when I went to sleep. #WCCO\n",
      "August has the most birthdays, February has the least and most of the serial killers are born in November!||-so dont mess up with me|#nov26\n",
      "Lol RT @user Wouldn't surprise me if Soldado bangs in a hatrick and we win 0-3 against Chelsea tonight .. The legend is back\n",
      "Pulis turned down #NUFC cos he wants to spend a load of money on 30 year old journeymen. Parish wouldn't let him & neither would MA. #cpfc\n",
      "Sending best wishes to all my coworkers at the 9AM this morning\n",
      "@user try having no internet for a month. Now I know how Ethiopians feel.\n",
      "Thanks @user for connecting. Always look forward to exchange thoughts n ideas with #entrepreneur working on #green n #sustainability\n",
      "Seems as if @user wants to endorse me on LinkedIn for  - any thoughts on this from the #OMCchat crowd?\n",
      "Love being made fun of\n",
      "Parking meter obviously forgot to get its own parking ticket.\n",
      "Heaven help the fool who did her wrong\n",
      "Just bartered for a bottle of rum in best one, and got it down from ¬£18 to ¬£14. Happy Fucking New Year to me!!\n",
      "Well it's always a good time losing at the Bay... @user @user @user\n",
      "I love when folks call Brady a system QB but are THE BIGGEST Peyton Manning fans. .\n",
      "@user Instead of playing the pompous \"do you know who I am card?\" , how about you actually make an educated rebuttal?\n",
      "Kind of love how I got a voicemail from my seat neighbor wondering where I was yet they constantly sell their ticket & I never ask\n",
      "I feel a nap in my near future. #NapTime\n",
      "The ever so caring @user gets to see the siege ending first. Great journalism.\n",
      "hmmm. I do wonder why Astec has one fewer employee? #lol\n",
      "@user so funny lolololol\n",
      "On my lunch break so sleepyüò¥\n",
      "@user @user More clean OR cleaner, never more cleaner\n",
      "Amen, that's due to them  having respect for themselves.\n",
      "Double standards are always a fun thing\n",
      "Oversleeping is the bestttt.\n",
      "I need a misadventure form because I broke my hand practising and rewriting this english essay 500 times\n",
      "@user #NoodleScene anyone? He was so zen there. . Oh! wait! But #deadHenry and #bouncebackAnnie. Silly me! All makes sense now!\n",
      "I love that when a female expresses herself in an emphatic manner, it's always attributed to her menstrual cycle. -Mags  #PMS\n",
      "These girls can wake up people from the dead!  #worth #watching\n",
      "Travel and tourism this morning.My favourite lesson whoooo\n",
      "To all u #deadbeatdads ur not worth a hair on our #kids heads.. Tough being a #singlemom but at least my #beautiful #daughter is loved by Me\n",
      "Aaaaaaaaand we're back in the ER. Hooray for no sleep!\n",
      "Just a had a Bruce Springsteen flashback. *shudder* @user @user @user @user @user\n",
      "Is Obamacare Slowing Health Care Spending?  via @user\n",
      "@user Ha! I don't have haters. Just a few misguided souls who thought my mentions were a bulletin board for their issues. ;)\n",
      "@user Ooooh only the 'economic' destruction of the country. Now that makes a world of a difference.\n",
      "Ask Mystic Mona YOUR question! Psychic View, weekdays at 9am (PDT) 347-850-1494 #BlogTalkRadio\n",
      "saturday class wee\n",
      "I have a VERY limited number of press seats available for a Meet Me There screening in Austin on January 21. Hit me up, press types.\n",
      "@user T-Mobile's CEO thinks the Apple Watch is going to be huge <-- I do, too.\n",
      "I love cold winter days cause I never know when my car decides not to start üòë\n",
      "This clinical psychology exam is gunna be the main cause of whatever mental disorder I develop\n",
      ".@BDUTT is at her best when she reports frm 'on the field'. Not that she is bad at studio but on field she is a true story teller.\n",
      "What a great person you are.\n",
      "@user Oh no, I've tipped Gamergates hand. Now you know our end game!\n",
      "@user @user Ya cause their country is calm and peaceful from Everyone arming themselves\n",
      "Reading a Victoria's Secret Fashion Show recap with a plate of French fries in front of me üçü\n",
      ".@Moz @user Woot woot! Whiteboard Friday's are my favorite Friday activity!\n",
      "Why is it so hard for people to cover their mouth when they cough?? Specially old people! Wtf, isn't it common curtesy? #coveryomouf #nasty\n",
      "@user People who commit crimes, resist cops, or attack cops are endangering their own lives. No respect for law or other people.\n",
      "Love coming to school knowing I have tests all day\n",
      "@user wow.. she really touched them with that tweet.\n",
      "Gawd! I love 9am lectures and 4-6pm lectures.\n",
      "My stomach is a Wonderland for gas inducing bacteria. #blessed\n",
      "Song of the Day: \"The Lights and Buzz\" - Jack's Mannequin.\n",
      "Younger siblings are okay. But then they do this irritating thing where they wake you at 5:15 to open presents. And that's just awesome\n",
      "@user I think I'm gonna check your music out later. Thanks‚ò∫\n",
      "May be cold tomorrow, December 28, 2014! A low of -7‚ÑÉ - dress warm!\n",
      "Love it when your typing at work and a spider comes out from the keyboard and hangs out between your fingers...  üôà\n",
      "The last Twolves game I was jacked for was right after the lockout in 2011 vs. OKC (Rubio's 1st game)... I wonder if I when I will again?\n",
      "@user looking forward to the time I have to traipse down the stairs to postie with a baby attached to my nipple! üò≥\n",
      "Currently writing about how I plan to stop procrastinating after leaving the paper untouched all day\n",
      "The ugly truth... #abuse  #enough #words\n",
      "Just ordered 10 new pairs of underwear from Victoria Secret üòç #yay\n",
      "@user A lot of ingredients. More specifically.... Like a lot a lot\n",
      "amazing how they are the one doing the ignoring, and think they are set free @user @user @user\n",
      "Ideology in a nutshell - the meaning of life in a sentence for every perspective.\n",
      "@user it's finally open XD I used a youtube video to help me :) Thanks very much ;)\n",
      "A whole day at NS w/clients. YAY.\n",
      "@user @user not playing out in the provinces like, oh, Mississippi.\n",
      "MVP goes to Concordia Wifi.\n",
      "I just love the NHS\n"
     ]
    }
   ],
   "source": [
    "indexList = [0,5,7,8,9,10,15,16,19,20,\n",
    "             23,24,30,34,35,36,37,38,39,40,\n",
    "             42,45,48,49,52,55,61,66,67,68,\n",
    "             69,74,75,76,78,79,80,84,87,88,\n",
    "             91,93,94,95,96,99,101,106,108,109,\n",
    "             110,111,115,116,117,119,120,121,123,125,\n",
    "             126,127,129,131,134,136,137,138,141,142,\n",
    "             146,153,155,157,159,160,161,163,165,166,\n",
    "             168,172,174,175,177,181,184,185,186,187,\n",
    "             191,192,193,194,196,207,208,220,228,234\n",
    "             ] # removed three non-irony for balance: 198,204,205\n",
    "dataset = pd.read_csv(\"datasets\\\\tweet_eval_irony_train.csv\")\n",
    "for index, row in dataset.iterrows():\n",
    "    if(index in indexList):\n",
    "        print(row[0])\n",
    "\n",
    "dataset = dataset.loc[indexList]\n",
    "#dataset.to_csv(\"manual_select_new.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>seeing ppl walking w/ crutches makes me really...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hey what do you know, one of the witnesses sup...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>You know it's going to be a great day when you...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Halfway thorough my workday ... Woooo</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Would like to thank my nephew for giving me hi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>@user it's finally open XD I used a youtube vi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>A whole day at NS w/clients. YAY.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>@user @user not playing out in the provinces l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>MVP goes to Concordia Wifi.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>I just love the NHS</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    seeing ppl walking w/ crutches makes me really...      1\n",
       "5    Hey what do you know, one of the witnesses sup...      1\n",
       "7    You know it's going to be a great day when you...      1\n",
       "8                Halfway thorough my workday ... Woooo      1\n",
       "9    Would like to thank my nephew for giving me hi...      1\n",
       "..                                                 ...    ...\n",
       "207  @user it's finally open XD I used a youtube vi...      0\n",
       "208                  A whole day at NS w/clients. YAY.      1\n",
       "220  @user @user not playing out in the provinces l...      1\n",
       "228                        MVP goes to Concordia Wifi.      1\n",
       "234                                I just love the NHS      1\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SMALL TEST CELL TO TEST DATASETS MANUALLY (pre-gpt)\n",
    "#dataset = pd.read_csv(\"datasets\\\\tweet_eval_irony_train.csv\")\n",
    "notIrony = 0\n",
    "irony = 0\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    if (row[1] == 1):\n",
    "        irony = irony + 1\n",
    "    else:\n",
    "        notIrony = notIrony + 1\n",
    "\n",
    "print(irony, notIrony)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores controller\n",
    "def scoresController(resultSetScores, gptcolumn, type):\n",
    "    if (type == 'binary'):\n",
    "        return scoresBinary(resultSetScores, gptcolumn)\n",
    "    elif(type == 'binaryYesNo'):\n",
    "        return scoresBinaryYesNo(resultSetScores, gptcolumn)\n",
    "    elif(type == 'confidence'):\n",
    "        return scoresBinaryConf(resultSetScores, gptcolumn)\n",
    "    elif(type == 'sure'):\n",
    "        return scoresBinarySure(resultSetScores, gptcolumn)\n",
    "    elif(type == 'sentimentchoice'):\n",
    "        return scoresSentChoice(resultSetScores, gptcolumn)\n",
    "    elif(type == 'percentage'):\n",
    "        return scoresPercentage(resultSetScores, gptcolumn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT Runtype Controller\n",
    "def gptRunType(data, systemPrompt, model, type):\n",
    "    if (type == 'sure'):\n",
    "        return gptAreYouSure(data, systemPrompt, model)\n",
    "    else:\n",
    "        return gptNoHistory(data, systemPrompt, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def actionsForRunType(linesWrite, result, type, resultRunNum, path):\n",
    "    if(type == 'confidence'):\n",
    "        linesWrite = linesWrite + [\n",
    "        'truepos confidence avg: ' + str(listAvg(result['tpConf'])) + '\\n',\n",
    "        'falsepos confidence avg: ' + str(listAvg(result['fpConf'])) + '\\n',\n",
    "        'falseneg confidence avg: ' + str(listAvg(result['fnConf'])) + '\\n',\n",
    "        'trueneg confidence avg: ' + str(listAvg(result['tnConf'])) + '\\n']\n",
    "        matrixPlot(result['tpConf'], result['fpConf'], result['fnConf'], result['tnConf'], path + '\\\\figures', resultRunNum)\n",
    "        return linesWrite\n",
    "    elif(type == 'sure'):\n",
    "        linesWrite = linesWrite + ['Sure about ' + str(result['tpSure'])  + ' true positives, ' + str(result['fpSure']) + ' false positives, ' + str(result['fnSure']) + ' false negatives, and ' + str(result['tnSure']) + ' true negatives.\\n']\n",
    "        matrixPlotSure(result['tp'], result['tpSure'], result['fp'], result['fpSure'], result['fn'], result['fnSure'], result['tn'], result['tnSure'], path + '\\\\figures', resultRunNum)\n",
    "        return linesWrite\n",
    "    else:\n",
    "        return linesWrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "if (re.match(r'(\\d{1,2}%?|(100(%?)))$', '0%')):\n",
    "    print(\"Yes\")\n",
    "else:\n",
    "    print(\"No\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System prompt: You are an irony detector. Respond with '1' (for yes) or '0' (for no) depending on whether you think the following statements are ironic.\n",
      "\n",
      "20 20.0 %\n",
      "40 40.0 %\n",
      "60 60.0 %\n",
      "80 80.0 %\n"
     ]
    }
   ],
   "source": [
    "# GPT CONTROLLER\n",
    "# runtypes = binary, confidence, sure, sentimentchoice, percentage\n",
    "runType = 'binary'\n",
    "datasetName = \"manual_select_new\"\n",
    "datasetPath = \"datasets\\\\\" + datasetName + \".csv\"\n",
    "data = pd.read_csv(datasetPath)\n",
    "data = data.head(100)\n",
    "\n",
    "amountOfRuns = 10\n",
    "\n",
    "alternate = 'default' # prompt engineering: selects the prompt in the alternate + 1th line of the text file. Set to'default' if going with default prompt\n",
    "\n",
    "results = []\n",
    "\n",
    "promptFile = open(\"prompts\\\\\" + runType + \".txt\") # selects the correct prompt from the file of prompts (prompt engineering)\n",
    "\n",
    "# select the right prompt from the file (used for prompt engineering)\n",
    "selected = False\n",
    "for i in promptFile:\n",
    "    altList = i.split(';')\n",
    "    alternateName = altList[0]\n",
    "    systemPrompt = altList[1]\n",
    "    if(alternateName == alternate):\n",
    "        selected = True\n",
    "        break\n",
    "\n",
    "#model = \"gpt-4\" #gpt-4o, gpt-4-turbo, gpt-4, and gpt-3.5-turbo\n",
    "#model = \"gpt-4\"\n",
    "model = \"gpt-3.5-turbo\"\n",
    "if(selected):\n",
    "    print('System prompt: ' + systemPrompt)\n",
    "    for x in range(amountOfRuns):\n",
    "        resultSet = gptRunType(data, systemPrompt, model, runType)\n",
    "        print('Run ' + str(x + 1) + ' done!')\n",
    "        results.append(resultSet)\n",
    "else:\n",
    "    print('No suitable prompt found. Please check input parameters.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "# create dataframe that contains the original tweet (column 0), the original classification (column 1) and the gpt classification of the tweet (column 2)\n",
    "resultSetAlt = data\n",
    "runNo = 1\n",
    "resultScores = []\n",
    "\n",
    "# take original dataset, add new columns that give classification for that line as returned by gpt\n",
    "for x in results:\n",
    "    string = 'gpt run no. ' + str(runNo)\n",
    "    runNo = runNo + 1\n",
    "    if (runType == 'sure'):\n",
    "        resultSetAlt[string] = x\n",
    "    else:\n",
    "        resultSetAlt[string] = x['classification']\n",
    "\n",
    "# calculate and save scores\n",
    "for x in range(amountOfRuns):\n",
    "    res = scoresController(resultSetAlt, x + 2, runType)\n",
    "    resultScores.append(res)\n",
    "\n",
    "# create folder for dataset, current date and time to sort results\n",
    "now = datetime.datetime.now()\n",
    "pathTime = \"results\\\\\"+ runType + \"\\\\\" + str(alternateName) + \"\\\\\" + datasetName + '\\\\' +  str(len(resultSetAlt)) + '\\\\' + model + '\\\\' + str(now.date()) + \"_\" + str(now.time().hour) + \"-\" + str(now.time().minute)\n",
    "if not os.path.exists(pathTime):\n",
    "    os.makedirs(pathTime)\n",
    "\n",
    "# create text file containing the relevant results from the experiment\n",
    "\n",
    "linesToWrite = ['Model used: ' + model + '\\n',\n",
    "                #'Model (given by last run): ' + str(results[(amountOfRuns - 1)]['model']) + '\\n',\n",
    "                'Prompt: ' + systemPrompt + '\\n']\n",
    "if (alternate == 0):\n",
    "    linesToWrite = linesToWrite + ['Alternate Prompt (prompt engineering): No' + '\\n']\n",
    "else:\n",
    "    linesToWrite = linesToWrite + ['Alternate Prompt (prompt engineering): ' + str(alternateName) + '\\n']\n",
    "\n",
    "linesToWrite = linesToWrite + ['Dataset: ' + datasetPath + '\\n',\n",
    "                'Amount of individual evaluations (sample size): ' + str(len(resultSetAlt)) + '\\n\\n']\n",
    "\n",
    "resultRuns = 0\n",
    "averageF1 = 0.0\n",
    "for res in resultScores:\n",
    "    errorString = 'Errors (not parsed): \\n'\n",
    "    for error in res['error']:\n",
    "        errorString = errorString + error + '\\n'\n",
    "\n",
    "    linesToWrite = linesToWrite + ['Results for run ' + str(resultRuns + 1) + ': \\n',\n",
    "        'Matrix:' + '\\n',\n",
    "        str(res['tp']) + '  ' + str(res['fp']) + '\\n',\n",
    "        str(res['fn']) + '  ' + str(res['tn']) + '\\n']\n",
    "    linesToWrite = actionsForRunType(linesToWrite, res, runType, resultRuns, pathTime)\n",
    "    linesToWrite = linesToWrite + ['Precision: ' + str(res['precision']) + '\\n',\n",
    "        'Recall: ' + str(res['recall']) + '\\n',\n",
    "        'F1-Score: ' + str(res['F1']) + '\\n\\n',\n",
    "        errorString + '\\n\\n']\n",
    "    averageF1 = averageF1 + res['F1']\n",
    "    resultRuns = resultRuns + 1\n",
    "    \n",
    "averageF1 = averageF1/resultRuns\n",
    "\n",
    "linesToWrite = linesToWrite + ['Average F1 score across ' + str(resultRuns) + ' runs: ' + str(averageF1)]\n",
    "\n",
    "file = open(pathTime + \"\\\\metadata.txt\", \"w\")\n",
    "file.writelines(linesToWrite)\n",
    "file.close()\n",
    "\n",
    "# save the original data evaluated as well as the results (all of which is in resultSetAlt) as a csv for review if required\n",
    "resultSetAlt.to_csv(pathTime + '\\\\results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
