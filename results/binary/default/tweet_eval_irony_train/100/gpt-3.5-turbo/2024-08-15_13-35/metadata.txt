Model used: gpt-3.5-turbo
Prompt: You are an irony detector. Respond with '1' (for yes) or '0' (for no) depending on whether you think the following statements are ironic.Alternate Prompt (prompt engineering): No
Dataset: datasets\tweet_eval_irony_train.csv
Amount of individual evaluations (sample size): 100

Results for run 1: 
Confusion Matrix:
46  3
37  14
Accuracy: 0.6
Precision: 0.5542168674698795
Recall: 0.9387755102040817
F1-Score: 0.6969696969696971

Errors (not parsed): 


Results for run 2: 
Confusion Matrix:
42  7
37  14
Accuracy: 0.56
Precision: 0.5316455696202531
Recall: 0.8571428571428571
F1-Score: 0.65625

Errors (not parsed): 


Results for run 3: 
Confusion Matrix:
43  6
33  18
Accuracy: 0.61
Precision: 0.5657894736842105
Recall: 0.8775510204081632
F1-Score: 0.6880000000000001

Errors (not parsed): 


Results for run 4: 
Confusion Matrix:
45  4
33  18
Accuracy: 0.63
Precision: 0.5769230769230769
Recall: 0.9183673469387755
F1-Score: 0.7086614173228346

Errors (not parsed): 


Results for run 5: 
Confusion Matrix:
45  4
34  17
Accuracy: 0.62
Precision: 0.569620253164557
Recall: 0.9183673469387755
F1-Score: 0.7031250000000001

Errors (not parsed): 


Results for run 6: 
Confusion Matrix:
46  3
35  16
Accuracy: 0.62
Precision: 0.5679012345679012
Recall: 0.9387755102040817
F1-Score: 0.7076923076923076

Errors (not parsed): 


Results for run 7: 
Confusion Matrix:
46  3
33  18
Accuracy: 0.64
Precision: 0.5822784810126582
Recall: 0.9387755102040817
F1-Score: 0.71875

Errors (not parsed): 


Results for run 8: 
Confusion Matrix:
44  5
36  15
Accuracy: 0.59
Precision: 0.55
Recall: 0.8979591836734694
F1-Score: 0.682170542635659

Errors (not parsed): 


Results for run 9: 
Confusion Matrix:
45  4
37  14
Accuracy: 0.59
Precision: 0.5487804878048781
Recall: 0.9183673469387755
F1-Score: 0.6870229007633588

Errors (not parsed): 


Results for run 10: 
Confusion Matrix:
43  6
35  16
Accuracy: 0.59
Precision: 0.5512820512820513
Recall: 0.8775510204081632
F1-Score: 0.6771653543307087

Errors (not parsed): 


Results for run 11: 
Confusion Matrix:
42  7
35  16
Accuracy: 0.58
Precision: 0.5454545454545454
Recall: 0.8571428571428571
F1-Score: 0.6666666666666665

Errors (not parsed): 


Results for run 12: 
Confusion Matrix:
43  6
31  20
Accuracy: 0.63
Precision: 0.581081081081081
Recall: 0.8775510204081632
F1-Score: 0.6991869918699187

Errors (not parsed): 


Results for run 13: 
Confusion Matrix:
45  4
30  21
Accuracy: 0.66
Precision: 0.6
Recall: 0.9183673469387755
F1-Score: 0.7258064516129031

Errors (not parsed): 


Results for run 14: 
Confusion Matrix:
45  4
34  17
Accuracy: 0.62
Precision: 0.569620253164557
Recall: 0.9183673469387755
F1-Score: 0.7031250000000001

Errors (not parsed): 


Results for run 15: 
Confusion Matrix:
46  3
32  19
Accuracy: 0.65
Precision: 0.5897435897435898
Recall: 0.9387755102040817
F1-Score: 0.7244094488188976

Errors (not parsed): 


Results for run 16: 
Confusion Matrix:
46  3
37  14
Accuracy: 0.6
Precision: 0.5542168674698795
Recall: 0.9387755102040817
F1-Score: 0.6969696969696971

Errors (not parsed): 


Results for run 17: 
Confusion Matrix:
44  5
33  18
Accuracy: 0.62
Precision: 0.5714285714285714
Recall: 0.8979591836734694
F1-Score: 0.6984126984126985

Errors (not parsed): 


Results for run 18: 
Confusion Matrix:
47  2
29  22
Accuracy: 0.69
Precision: 0.618421052631579
Recall: 0.9591836734693877
F1-Score: 0.752

Errors (not parsed): 


Results for run 19: 
Confusion Matrix:
44  5
40  11
Accuracy: 0.55
Precision: 0.5238095238095238
Recall: 0.8979591836734694
F1-Score: 0.6616541353383458

Errors (not parsed): 


Results for run 20: 
Confusion Matrix:
46  3
37  14
Accuracy: 0.6
Precision: 0.5542168674698795
Recall: 0.9387755102040817
F1-Score: 0.6969696969696971

Errors (not parsed): 


Average Accuracy score across 20 runs: 0.6124999999999999
Average Precision score across 20 runs: 0.5653214923891335
Average Recall score across 20 runs: 0.9112244897959183
Average F1 score across 20 runs: 0.6975504003186697