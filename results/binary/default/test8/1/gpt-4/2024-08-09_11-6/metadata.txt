Model used: gpt-4
Prompt: You are an irony detector. Respond with '1' (for yes) or '0' (for no) depending on whether you think the following statements are ironic.Alternate Prompt (prompt engineering): No
Dataset: datasets\test8.csv
Amount of individual evaluations (sample size): 1

Results for run 1: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Results for run 2: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Results for run 3: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Results for run 4: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Results for run 5: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Results for run 6: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Results for run 7: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Results for run 8: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Results for run 9: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Results for run 10: 
Confusion Matrix:
0  1
0  0
Accuracy: 0.0
Precision: 0
Recall: 0.0
F1-Score: 0

Errors (not parsed): 


Average Accuracy score across 10 runs: 0.0
Average Precision score across 10 runs: 0.0
Average Recall score across 10 runs: 0.0
Average F1 score across 10 runs: 0.0