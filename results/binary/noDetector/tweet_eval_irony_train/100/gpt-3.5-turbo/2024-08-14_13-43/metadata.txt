Model used: gpt-3.5-turbo
Prompt: Respond with '1' (for yes) or '0' (for no) depending on whether you think the following statements are ironic.Alternate Prompt (prompt engineering): noDetector
Dataset: datasets\tweet_eval_irony_train.csv
Amount of individual evaluations (sample size): 100

Results for run 1: 
Confusion Matrix:
34  15
23  28
Accuracy: 0.62
Precision: 0.5964912280701754
Recall: 0.6938775510204082
F1-Score: 0.6415094339622641

Errors (not parsed): 


Results for run 2: 
Confusion Matrix:
34  15
23  28
Accuracy: 0.62
Precision: 0.5964912280701754
Recall: 0.6938775510204082
F1-Score: 0.6415094339622641

Errors (not parsed): 


Results for run 3: 
Confusion Matrix:
34  15
24  27
Accuracy: 0.61
Precision: 0.5862068965517241
Recall: 0.6938775510204082
F1-Score: 0.6355140186915887

Errors (not parsed): 


Results for run 4: 
Confusion Matrix:
34  15
19  32
Accuracy: 0.66
Precision: 0.6415094339622641
Recall: 0.6938775510204082
F1-Score: 0.6666666666666666

Errors (not parsed): 


Results for run 5: 
Confusion Matrix:
37  12
22  29
Accuracy: 0.66
Precision: 0.6271186440677966
Recall: 0.7551020408163265
F1-Score: 0.6851851851851852

Errors (not parsed): 


Results for run 6: 
Confusion Matrix:
36  13
20  31
Accuracy: 0.67
Precision: 0.6428571428571429
Recall: 0.7346938775510204
F1-Score: 0.6857142857142857

Errors (not parsed): 


Results for run 7: 
Confusion Matrix:
33  16
26  25
Accuracy: 0.58
Precision: 0.559322033898305
Recall: 0.673469387755102
F1-Score: 0.611111111111111

Errors (not parsed): 


Results for run 8: 
Confusion Matrix:
34  15
24  27
Accuracy: 0.61
Precision: 0.5862068965517241
Recall: 0.6938775510204082
F1-Score: 0.6355140186915887

Errors (not parsed): 


Results for run 9: 
Confusion Matrix:
33  16
18  33
Accuracy: 0.66
Precision: 0.6470588235294118
Recall: 0.673469387755102
F1-Score: 0.66

Errors (not parsed): 


Results for run 10: 
Confusion Matrix:
40  9
24  27
Accuracy: 0.67
Precision: 0.625
Recall: 0.8163265306122449
F1-Score: 0.7079646017699115

Errors (not parsed): 


Results for run 11: 
Confusion Matrix:
39  10
19  32
Accuracy: 0.71
Precision: 0.6724137931034483
Recall: 0.7959183673469388
F1-Score: 0.7289719626168225

Errors (not parsed): 


Results for run 12: 
Confusion Matrix:
37  12
24  27
Accuracy: 0.64
Precision: 0.6065573770491803
Recall: 0.7551020408163265
F1-Score: 0.6727272727272727

Errors (not parsed): 


Results for run 13: 
Confusion Matrix:
34  15
20  31
Accuracy: 0.65
Precision: 0.6296296296296297
Recall: 0.6938775510204082
F1-Score: 0.6601941747572815

Errors (not parsed): 


Results for run 14: 
Confusion Matrix:
37  12
20  31
Accuracy: 0.68
Precision: 0.6491228070175439
Recall: 0.7551020408163265
F1-Score: 0.6981132075471698

Errors (not parsed): 


Results for run 15: 
Confusion Matrix:
32  17
20  31
Accuracy: 0.63
Precision: 0.6153846153846154
Recall: 0.6530612244897959
F1-Score: 0.6336633663366337

Errors (not parsed): 


Results for run 16: 
Confusion Matrix:
38  11
24  27
Accuracy: 0.65
Precision: 0.6129032258064516
Recall: 0.7755102040816326
F1-Score: 0.6846846846846848

Errors (not parsed): 


Results for run 17: 
Confusion Matrix:
32  17
20  31
Accuracy: 0.63
Precision: 0.6153846153846154
Recall: 0.6530612244897959
F1-Score: 0.6336633663366337

Errors (not parsed): 


Results for run 18: 
Confusion Matrix:
37  12
18  33
Accuracy: 0.7
Precision: 0.6727272727272727
Recall: 0.7551020408163265
F1-Score: 0.7115384615384616

Errors (not parsed): 


Results for run 19: 
Confusion Matrix:
38  11
17  34
Accuracy: 0.72
Precision: 0.6909090909090909
Recall: 0.7755102040816326
F1-Score: 0.7307692307692308

Errors (not parsed): 


Results for run 20: 
Confusion Matrix:
36  13
21  30
Accuracy: 0.66
Precision: 0.631578947368421
Recall: 0.7346938775510204
F1-Score: 0.6792452830188679

Errors (not parsed): 


Average Accuracy score across 20 runs: 0.6515000000000001
Average Precision score across 20 runs: 0.6252436850969494
Average Recall score across 20 runs: 0.7234693877551022
Average F1 score across 20 runs: 0.6702129883043962