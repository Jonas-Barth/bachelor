Model used: gpt-4
Prompt: You are an irony detector. Respond with '1' (for yes) or '0' (for no) depending on whether you think the following statements are ironic. Steamship.
Alternate Prompt (prompt engineering): random
Dataset: datasets\tweet_eval_irony_train.csv
Amount of individual evaluations (sample size): 100

Results for run 1: 
Matrix:
33  8
16  43
Precision: 0.8048780487804879
Recall: 0.673469387755102
F1-Score: 0.7333333333333334

Errors (not parsed): 


Results for run 2: 
Matrix:
32  7
17  44
Precision: 0.8205128205128205
Recall: 0.6530612244897959
F1-Score: 0.7272727272727272

Errors (not parsed): 


Results for run 3: 
Matrix:
34  7
15  44
Precision: 0.8292682926829268
Recall: 0.6938775510204082
F1-Score: 0.7555555555555555

Errors (not parsed): 


Results for run 4: 
Matrix:
33  7
16  44
Precision: 0.825
Recall: 0.673469387755102
F1-Score: 0.7415730337078652

Errors (not parsed): 


Results for run 5: 
Matrix:
32  6
17  45
Precision: 0.8421052631578947
Recall: 0.6530612244897959
F1-Score: 0.735632183908046

Errors (not parsed): 


Results for run 6: 
Matrix:
31  9
18  42
Precision: 0.775
Recall: 0.6326530612244898
F1-Score: 0.6966292134831462

Errors (not parsed): 


Results for run 7: 
Matrix:
32  7
17  44
Precision: 0.8205128205128205
Recall: 0.6530612244897959
F1-Score: 0.7272727272727272

Errors (not parsed): 


Results for run 8: 
Matrix:
33  4
16  47
Precision: 0.8918918918918919
Recall: 0.673469387755102
F1-Score: 0.7674418604651163

Errors (not parsed): 


Results for run 9: 
Matrix:
31  7
18  44
Precision: 0.8157894736842105
Recall: 0.6326530612244898
F1-Score: 0.7126436781609196

Errors (not parsed): 


Results for run 10: 
Matrix:
33  5
16  46
Precision: 0.868421052631579
Recall: 0.673469387755102
F1-Score: 0.7586206896551724

Errors (not parsed): 


Average F1 score across 10 runs: 0.735597500281461