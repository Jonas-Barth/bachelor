Model used: gpt-3.5-turbo
Prompt: You are an irony detector. Respond with 'Yes' or 'No' depending on whether you think the following statements are ironic.

Alternate Prompt (prompt engineering): yesNo
Dataset: datasets\tweet_eval_irony_train.csv
Amount of individual evaluations (sample size): 100

Results for run 1: 
Matrix:
27  15
22  36
Accuracy: 0.63
Precision: 0.6428571428571429
Recall: 0.5510204081632653
F1-Score: 0.5934065934065934

Errors (not parsed): 


Results for run 2: 
Matrix:
31  11
18  40
Accuracy: 0.71
Precision: 0.7380952380952381
Recall: 0.6326530612244898
F1-Score: 0.6813186813186813

Errors (not parsed): 


Results for run 3: 
Matrix:
29  14
20  37
Accuracy: 0.66
Precision: 0.6744186046511628
Recall: 0.5918367346938775
F1-Score: 0.6304347826086958

Errors (not parsed): 


Results for run 4: 
Matrix:
30  16
19  35
Accuracy: 0.65
Precision: 0.6521739130434783
Recall: 0.6122448979591837
F1-Score: 0.631578947368421

Errors (not parsed): 


Results for run 5: 
Matrix:
29  13
20  38
Accuracy: 0.67
Precision: 0.6904761904761905
Recall: 0.5918367346938775
F1-Score: 0.6373626373626373

Errors (not parsed): 


Results for run 6: 
Matrix:
29  12
20  39
Accuracy: 0.68
Precision: 0.7073170731707317
Recall: 0.5918367346938775
F1-Score: 0.6444444444444445

Errors (not parsed): 


Results for run 7: 
Matrix:
36  11
13  40
Accuracy: 0.76
Precision: 0.7659574468085106
Recall: 0.7346938775510204
F1-Score: 0.7499999999999999

Errors (not parsed): 


Results for run 8: 
Matrix:
30  12
19  39
Accuracy: 0.69
Precision: 0.7142857142857143
Recall: 0.6122448979591837
F1-Score: 0.6593406593406593

Errors (not parsed): 


Results for run 9: 
Matrix:
29  14
20  37
Accuracy: 0.66
Precision: 0.6744186046511628
Recall: 0.5918367346938775
F1-Score: 0.6304347826086958

Errors (not parsed): 


Results for run 10: 
Matrix:
27  15
22  36
Accuracy: 0.63
Precision: 0.6428571428571429
Recall: 0.5510204081632653
F1-Score: 0.5934065934065934

Errors (not parsed): 


Average F1 score across 10 runs: 0.6451728121865422