Model used: gpt-4
Prompt: You are an irony detector. Respond with '1' (for yes) or '0' (for no) depending on whether you think the following statements are ironic. An example of an ironic statement: "Always fun when buses don't turn up! It's my favorite waiting outside in the freezing cold for them for like half an hour"
Alternate Prompt (prompt engineering): oneshot1
Dataset: datasets\tweet_eval_irony_train.csv
Amount of individual evaluations (sample size): 100

Results for run 1: 
Confusion Matrix:
31  18
6  45
Accuracy: 0.76
Precision: 0.8378378378378378
Recall: 0.6326530612244898
F1-Score: 0.7209302325581396

Errors (not parsed): 


Results for run 2: 
Confusion Matrix:
34  15
7  44
Accuracy: 0.78
Precision: 0.8292682926829268
Recall: 0.6938775510204082
F1-Score: 0.7555555555555555

Errors (not parsed): 


Results for run 3: 
Confusion Matrix:
33  16
6  45
Accuracy: 0.78
Precision: 0.8461538461538461
Recall: 0.673469387755102
F1-Score: 0.75

Errors (not parsed): 


Results for run 4: 
Confusion Matrix:
34  15
7  44
Accuracy: 0.78
Precision: 0.8292682926829268
Recall: 0.6938775510204082
F1-Score: 0.7555555555555555

Errors (not parsed): 


Results for run 5: 
Confusion Matrix:
31  18
6  45
Accuracy: 0.76
Precision: 0.8378378378378378
Recall: 0.6326530612244898
F1-Score: 0.7209302325581396

Errors (not parsed): 


Results for run 6: 
Confusion Matrix:
33  16
5  46
Accuracy: 0.79
Precision: 0.868421052631579
Recall: 0.673469387755102
F1-Score: 0.7586206896551724

Errors (not parsed): 


Results for run 7: 
Confusion Matrix:
36  13
6  45
Accuracy: 0.81
Precision: 0.8571428571428571
Recall: 0.7346938775510204
F1-Score: 0.7912087912087913

Errors (not parsed): 


Results for run 8: 
Confusion Matrix:
35  14
6  45
Accuracy: 0.8
Precision: 0.8536585365853658
Recall: 0.7142857142857143
F1-Score: 0.7777777777777778

Errors (not parsed): 


Results for run 9: 
Confusion Matrix:
32  17
7  44
Accuracy: 0.76
Precision: 0.8205128205128205
Recall: 0.6530612244897959
F1-Score: 0.7272727272727272

Errors (not parsed): 


Results for run 10: 
Confusion Matrix:
32  17
8  43
Accuracy: 0.75
Precision: 0.8
Recall: 0.6530612244897959
F1-Score: 0.7191011235955055

Errors (not parsed): 


Average Accuracy score across 10 runs: 0.777
Average Precision score across 10 runs: 0.8380101374067997
Average Recall score across 10 runs: 0.6755102040816326
Average F1 score across 10 runs: 0.7476952685737365