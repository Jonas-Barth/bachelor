Model used: gpt-4
Prompt: You are an irony detector. Respond to messages with your evaluation of how ironic the message is, given only as a percentage, such as '50%'.
Alternate Prompt (prompt engineering): No
Dataset: datasets\tweet_eval_irony_train.csv
Amount of individual evaluations (sample size): 100

Results for run 1: 
Confusion Matrix:
29  20
4  46
Accuracy: 0.7575757575757576
Precision: 0.8787878787878788
Recall: 0.5918367346938775
F1-Score: 0.7073170731707316

Errors (not parsed): 
93: This message lacks enough context to determine the level of irony. Please provide more information.


Results for run 2: 
Confusion Matrix:
29  20
2  48
Accuracy: 0.7777777777777778
Precision: 0.9354838709677419
Recall: 0.5918367346938775
F1-Score: 0.7249999999999999

Errors (not parsed): 
93: Insufficient data. Please provide more context.


Results for run 3: 
Confusion Matrix:
26  23
2  48
Accuracy: 0.7474747474747475
Precision: 0.9285714285714286
Recall: 0.5306122448979592
F1-Score: 0.6753246753246754

Errors (not parsed): 
93: Your message does not contain sufficient information for me to determine its level of irony. Please provide more context.


Results for run 4: 
Confusion Matrix:
30  19
3  47
Accuracy: 0.7777777777777778
Precision: 0.9090909090909091
Recall: 0.6122448979591837
F1-Score: 0.7317073170731708

Errors (not parsed): 
93: Please provide more context or complete sentence so I can give an accurate evaluation of irony.


Results for run 5: 
Confusion Matrix:
29  20
2  48
Accuracy: 0.7777777777777778
Precision: 0.9354838709677419
Recall: 0.5918367346938775
F1-Score: 0.7249999999999999

Errors (not parsed): 
93: As an AI, I need concrete statements to analyze irony. Based on the given text, I cannot provide a percentage of irony. Please provide a statement or situation.


Results for run 6: 
Confusion Matrix:
24  25
3  47
Accuracy: 0.7171717171717171
Precision: 0.8888888888888888
Recall: 0.4897959183673469
F1-Score: 0.631578947368421

Errors (not parsed): 
93: As an AI, I need specific information or a statement in order to analyze for irony. Please provide more context.


Results for run 7: 
Confusion Matrix:
27  22
3  47
Accuracy: 0.7474747474747475
Precision: 0.9
Recall: 0.5510204081632653
F1-Score: 0.6835443037974683

Errors (not parsed): 
93: Please provide more context, as there's insufficient information to determine irony.


Results for run 8: 
Confusion Matrix:
30  19
2  48
Accuracy: 0.7878787878787878
Precision: 0.9375
Recall: 0.6122448979591837
F1-Score: 0.7407407407407408

Errors (not parsed): 
93: Insufficient data. Please provide more context or elaboration for a proper evaluation of irony.


Results for run 9: 
Confusion Matrix:
29  20
2  48
Accuracy: 0.7777777777777778
Precision: 0.9354838709677419
Recall: 0.5918367346938775
F1-Score: 0.7249999999999999

Errors (not parsed): 
93: Without knowing the specific context, irony evaluation is impossible. Please provide a complete message or statement.


Results for run 10: 
Confusion Matrix:
30  19
2  48
Accuracy: 0.7878787878787878
Precision: 0.9375
Recall: 0.6122448979591837
F1-Score: 0.7407407407407408

Errors (not parsed): 
93: Without additional context, ironic content cannot be evaluated. Please provide more content.


Average Accuracy score across 10 runs: 0.7656565656565657
Average Precision score across 10 runs: 0.9186790718242331
Average Recall score across 10 runs: 0.5775510204081633
Average F1 score across 10 runs: 0.7085953798215948